{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd14a571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e9b1da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cb6a7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dataset location\n",
    "data_dir = \"images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5f9f70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced data augmentation\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98e10642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = ImageFolder(root=data_dir, transform=train_transforms)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "val_dataset.dataset.transform = val_transforms\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b20464b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lenue/Desktop/IDMYBIRD/.birds/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/lenue/Desktop/IDMYBIRD/.birds/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet50\n",
    "import torch.nn as nn\n",
    "\n",
    "# Load pretrained model\n",
    "model = resnet50(pretrained=True).to(device)  # Move to CUDA \n",
    "\n",
    "\n",
    "model.fc = nn.Linear(model.fc.in_features, 202).to(device)  # Move this new layer to the same device\n",
    "\n",
    "# Step 3: Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)  \n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)  # Reduce LR every 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6a4b350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Training Loop\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=20):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        scheduler.step()  \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Validation Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c1dadd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12, Loss: 3.3004\n",
      "Validation Accuracy: 55.13%\n",
      "Epoch 2/12, Loss: 1.1947\n",
      "Validation Accuracy: 70.19%\n",
      "Epoch 3/12, Loss: 0.5371\n",
      "Validation Accuracy: 74.98%\n",
      "Epoch 4/12, Loss: 0.2265\n",
      "Validation Accuracy: 80.41%\n",
      "Epoch 5/12, Loss: 0.1617\n",
      "Validation Accuracy: 80.79%\n",
      "Epoch 6/12, Loss: 0.1258\n",
      "Validation Accuracy: 81.59%\n",
      "Epoch 7/12, Loss: 0.1053\n",
      "Validation Accuracy: 81.68%\n",
      "Epoch 8/12, Loss: 0.1019\n",
      "Validation Accuracy: 81.04%\n",
      "Epoch 9/12, Loss: 0.0990\n",
      "Validation Accuracy: 81.55%\n",
      "Epoch 10/12, Loss: 0.0964\n",
      "Validation Accuracy: 81.55%\n",
      "Epoch 11/12, Loss: 0.0944\n",
      "Validation Accuracy: 81.26%\n",
      "Epoch 12/12, Loss: 0.0947\n",
      "Validation Accuracy: 81.47%\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b8846ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"bird_model_v2.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".birds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
